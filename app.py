# Importa o Streamlit - framework para criar aplica√ß√µes web interativas em Python
# Importa ChatGroq - classe que faz a conex√£o com a API da Groq para usar modelos de LLM
# Importa ChatPromptTemplate - classe para criar templates de prompts estruturados
# Importa StrOutputParser - parser que converte a resposta do modelo em string
# Importa load_dotenv - fun√ß√£o que carrega vari√°veis de ambiente do arquivo .env
# Executa a fun√ß√£o para carregar as vari√°veis do arquivo .env (como GROQ_API_KEY)
import streamlit as st
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv
load_dotenv()

## === CONEX√ÉO COM A LLM === ##
id_model = "llama-3.3-70b-versatile" # Define o id da llm que ser√° utilizada (Llama 3.3 70B Versatile) 
llm = ChatGroq(         # Cria a inst√¢ncia do ChatGroq com os par√¢metros necess√°rios
    model=id_model,     # Define o modelo a ser utilizado
    temperature=0.7,    # Controla temperatura/criatividade (0=conservador, 1=criativo)
    max_tokens=None,    # N√∫mero m√°ximo de tokens na resposta (None=sem limite)
    timeout=None,       # Tempo m√°ximo de espera (None=sem limite)
    max_retries=2,      # N√∫mero de tentativas em caso de erro
)

## === FUN√á√ÉO DE GERA√á√ÉO DE CONTE√öDO === ##
def llm_generate(llm, prompt):
  template = ChatPromptTemplate.from_messages([
      ("system", "Voc√™ √© um especialista em marketing digital com foco em SEO e escrita persuasiva."),
      ("human", "{prompt}"),
  ])

  chain = template | llm | StrOutputParser()
  # Cria uma cadeia (chain) que executa sequencialmente:
  # 1. template - formata o prompt
  # 2. llm - envia para o modelo e recebe resposta
  # 3. StrOutputParser - converte a resposta em string

  res = chain.invoke({"prompt": prompt})
  # Executa a cadeia passando o prompt como par√¢metro
  return res
  # Retorna o texto gerado

## === INTERFACE COM STREAMLIT === ##
# Configura√ß√£o das propriedades da p√°gina
st.set_page_config(page_title = "Gerador de conte√∫do ü§ñ", page_icon="ü§ñ")
st.title("Gerador de conte√∫do")

# Campos do formul√°rio
topic = st.text_input("Tema:", placeholder="Ex: sa√∫de mental, alimenta√ß√£o saud√°vel, preven√ß√£o, etc.")
platform = st.selectbox("Plataforma:", ['Instagram', 'Facebook', 'LinkedIn', 'Blog', 'E-mail'])
tone = st.selectbox("Tom:", ['Normal', 'Informativo', 'Inspirador', 'Urgente', 'Informal'])
length = st.selectbox("Tamanho:", ['Curto', 'M√©dio', 'Longo'])
audience = st.selectbox("P√∫blico-alvo:", ['Geral', 'Jovens adultos', 'Fam√≠lias', 'Idosos', 'Adolescentes'])
#cta = st.checkbox("Incluir CTA")
cta = st.text_input("Chamada para A√ß√£o (CTA):", placeholder="Ex: Saiba mais, Inscreva-se, Compre agora...")
hashtags = st.checkbox("Retornar Hashtags")
keywords = st.text_area("Palavras-chave (SEO):", placeholder="Ex: bem-estar, medicina preventiva...")

## === PROCESSAMENTO E GERA√á√ÉO === ##
if st.button("Gerar conte√∫do"):
  
  # Constr√≥i o prompt final com todas as informa√ß√µes fornecidas pelo usu√°rio
  prompt = f"""
  Escreva um texto com SEO otimizado sobre o tema '{topic}'.
  Retorne em sua resposta apenas o texto final e n√£o inclua ela dentro de aspas.
  - Onde ser√° publicado: {platform}.
  - Tom: {tone}.
  - P√∫blico-alvo: {audience}.
  - Comprimento: {length}.
  - {"Inclua ao final do texto esta cahamada para a√ß√£o:" + cta if cta else "N√£o inclua chamada para a√ß√£o"}
  - {"Retorne ao final do texto hashtags relevantes." if hashtags else "N√£o inclua hashtags."}
  {"- Palavras-chave que devem estar presentes nesse texto (para SEO): " + keywords if keywords else ""}
  """

# Bloco para capturar poss√≠veis erros durante a gera√ß√£o
  try:
      res = llm_generate(llm, prompt)
      st.markdown(res)
  except Exception as e:
      st.error(f"Erro: {e}")